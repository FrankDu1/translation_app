# GPUæœºå™¨éƒ¨ç½²è„šæœ¬ (PowerShellç‰ˆæœ¬)
# ä½¿ç”¨æ–¹æ³•: .\deploy_gpu.ps1 [æ­¥éª¤]

param(
    [string]$Step = "help"
)

# é¢œè‰²å‡½æ•°
function Write-ColorOutput {
    param(
        [string]$Message,
        [string]$Color = "White"
    )
    Write-Host $Message -ForegroundColor $Color
}

function Log-Info {
    param([string]$Message)
    Write-ColorOutput "[INFO] $Message" "Green"
}

function Log-Warn {
    param([string]$Message)
    Write-ColorOutput "[WARN] $Message" "Yellow"
}

function Log-Error {
    param([string]$Message)
    Write-ColorOutput "[ERROR] $Message" "Red"
}

function Log-Step {
    param([string]$Message)
    Write-ColorOutput "[STEP] $Message" "Blue"
}

# æ£€æŸ¥GPUç¯å¢ƒ
function Test-GpuEnvironment {
    Log-Step "æ£€æŸ¥GPUç¯å¢ƒ..."
    
    try {
        $gpuInfo = nvidia-smi --query-gpu=name,memory.total,memory.used --format=csv,noheader,nounits
        Log-Info "GPUçŠ¶æ€:"
        Write-Host $gpuInfo
    } catch {
        Log-Error "æœªæ‰¾åˆ°nvidia-smiï¼Œè¯·å®‰è£…NVIDIAé©±åŠ¨"
        exit 1
    }
    
    # æ£€æŸ¥NVIDIA Dockeræ”¯æŒ
    try {
        docker run --rm --gpus all nvidia/cuda:11.8-base-ubuntu20.04 nvidia-smi | Out-Null
        Log-Info "âœ… GPUç¯å¢ƒæ£€æŸ¥é€šè¿‡"
    } catch {
        Log-Error "NVIDIA Dockeræ”¯æŒå¼‚å¸¸ï¼Œè¯·å®‰è£…nvidia-docker2"
        exit 1
    }
}

# å‡†å¤‡ç¯å¢ƒ
function Initialize-Environment {
    Log-Step "å‡†å¤‡ç¯å¢ƒé…ç½®..."
    
    # å¤åˆ¶ç¯å¢ƒå˜é‡æ–‡ä»¶
    if (-not (Test-Path ".env")) {
        Copy-Item ".env.gpu.example" ".env"
        Log-Info "å·²åˆ›å»º .env æ–‡ä»¶ï¼Œè¯·æ ¹æ®éœ€è¦ä¿®æ”¹é…ç½®"
    } else {
        Log-Info ".env æ–‡ä»¶å·²å­˜åœ¨"
    }
    
    # åˆ›å»ºå¿…è¦ç›®å½•
    $directories = @(
        "models\ocr", "models\nmt", "models\vision", 
        "models\huggingface", "models\diffusers",
        "temp\uploads", "temp\processed", "logs"
    )
    
    foreach ($dir in $directories) {
        if (-not (Test-Path $dir)) {
            New-Item -Path $dir -ItemType Directory -Force | Out-Null
        }
    }
    
    Log-Info "âœ… ç¯å¢ƒå‡†å¤‡å®Œæˆ"
}

# æ„å»ºé•œåƒ
function Build-DockerImages {
    Log-Step "æ„å»ºDockeré•œåƒ..."
    
    Log-Info "æ„å»ºOCRæœåŠ¡é•œåƒ..."
    docker compose -f docker-compose.gpu.yml build ocr-service
    
    Log-Info "æ„å»ºç¿»è¯‘æœåŠ¡é•œåƒ..."
    docker compose -f docker-compose.gpu.yml build nmt-service
    
    # æ£€æŸ¥æ˜¯å¦æœ‰VisionæœåŠ¡
    $services = docker compose -f docker-compose.gpu.yml config --services
    if ($services -contains "vision-service") {
        Log-Info "æ„å»ºVisionæœåŠ¡é•œåƒ..."
        docker compose -f docker-compose.gpu.yml build vision-service
    }
    
    Log-Info "âœ… é•œåƒæ„å»ºå®Œæˆ"
}

# ä¸‹è½½æ¨¡å‹
function Download-Models {
    Log-Step "ä¸‹è½½AIæ¨¡å‹..."
    
    # å¯åŠ¨Ollama
    Log-Info "å¯åŠ¨OllamaæœåŠ¡..."
    docker compose -f docker-compose.gpu.yml up -d ollama
    
    # ç­‰å¾…Ollamaå¯åŠ¨
    Log-Info "ç­‰å¾…OllamaæœåŠ¡å°±ç»ª..."
    $timeout = 60
    $elapsed = 0
    
    do {
        try {
            $response = Invoke-WebRequest -Uri "http://localhost:11434/api/tags" -TimeoutSec 2 -ErrorAction Stop
            if ($response.StatusCode -eq 200) {
                break
            }
        } catch {
            Start-Sleep -Seconds 2
            $elapsed += 2
            Write-Host "." -NoNewline
        }
    } while ($elapsed -lt $timeout)
    
    Write-Host ""
    
    if ($elapsed -ge $timeout) {
        Log-Error "OllamaæœåŠ¡å¯åŠ¨è¶…æ—¶"
        return
    }
    
    # ä¸‹è½½æ¨¡å‹
    Log-Info "ä¸‹è½½Llamaæ¨¡å‹..."
    docker compose -f docker-compose.gpu.yml exec ollama ollama pull llama3.2:latest
    
    Log-Info "ä¸‹è½½Qwenæ¨¡å‹..."
    try {
        docker compose -f docker-compose.gpu.yml exec ollama ollama pull qwen2.5:latest
    } catch {
        Log-Warn "Qwenæ¨¡å‹ä¸‹è½½å¤±è´¥ï¼Œå¯è·³è¿‡"
    }
    
    Log-Info "âœ… æ¨¡å‹ä¸‹è½½å®Œæˆ"
}

# å¯åŠ¨æœåŠ¡
function Start-GpuServices {
    Log-Step "å¯åŠ¨GPUæœåŠ¡..."
    
    # å¯åŠ¨æ ¸å¿ƒæœåŠ¡
    Log-Info "å¯åŠ¨æ ¸å¿ƒæœåŠ¡..."
    docker compose -f docker-compose.gpu.yml up -d ocr-service nmt-service ollama
    
    # ç­‰å¾…æœåŠ¡å¯åŠ¨
    Log-Info "ç­‰å¾…æœåŠ¡å¯åŠ¨..."
    Start-Sleep -Seconds 30
    
    # æ£€æŸ¥æœåŠ¡çŠ¶æ€
    Log-Info "æ£€æŸ¥æœåŠ¡çŠ¶æ€..."
    docker compose -f docker-compose.gpu.yml ps
    
    Log-Info "âœ… æœåŠ¡å¯åŠ¨å®Œæˆ"
}

# å¥åº·æ£€æŸ¥
function Test-ServiceHealth {
    Log-Step "æ‰§è¡Œå¥åº·æ£€æŸ¥..."
    
    $services = @(
        @{Url="http://localhost:7010/health"; Name="OCRæœåŠ¡"},
        @{Url="http://localhost:7020/health"; Name="ç¿»è¯‘æœåŠ¡"},
        @{Url="http://localhost:11434/api/tags"; Name="OllamaæœåŠ¡"}
    )
    
    foreach ($service in $services) {
        try {
            $response = Invoke-WebRequest -Uri $service.Url -TimeoutSec 10 -ErrorAction Stop
            if ($response.StatusCode -eq 200) {
                Log-Info "âœ… $($service.Name) å¥åº·æ£€æŸ¥é€šè¿‡"
            } else {
                Log-Error "âŒ $($service.Name) å¥åº·æ£€æŸ¥å¤±è´¥"
            }
        } catch {
            Log-Error "âŒ $($service.Name) å¥åº·æ£€æŸ¥å¤±è´¥"
            Log-Info "å°è¯•æŸ¥çœ‹æ—¥å¿—: docker compose -f docker-compose.gpu.yml logs"
        }
    }
}

# æ˜¾ç¤ºä½¿ç”¨è¯´æ˜
function Show-Help {
    Write-Host "GPUæœºå™¨éƒ¨ç½²è„šæœ¬ä½¿ç”¨è¯´æ˜:" -ForegroundColor Cyan
    Write-Host ""
    Write-Host "  .\deploy_gpu.ps1 [æ­¥éª¤]" -ForegroundColor White
    Write-Host ""
    Write-Host "å¯ç”¨æ­¥éª¤:" -ForegroundColor Yellow
    Write-Host "  check      - æ£€æŸ¥GPUç¯å¢ƒ"
    Write-Host "  prepare    - å‡†å¤‡ç¯å¢ƒé…ç½®" 
    Write-Host "  build      - æ„å»ºDockeré•œåƒ"
    Write-Host "  models     - ä¸‹è½½AIæ¨¡å‹"
    Write-Host "  start      - å¯åŠ¨æœåŠ¡"
    Write-Host "  health     - å¥åº·æ£€æŸ¥"
    Write-Host "  all        - æ‰§è¡Œå®Œæ•´éƒ¨ç½²æµç¨‹"
    Write-Host "  logs       - æŸ¥çœ‹æœåŠ¡æ—¥å¿—"
    Write-Host "  status     - æŸ¥çœ‹æœåŠ¡çŠ¶æ€"
    Write-Host "  stop       - åœæ­¢æœåŠ¡"
    Write-Host "  clean      - æ¸…ç†ç¯å¢ƒ"
    Write-Host ""
    Write-Host "ç¤ºä¾‹:" -ForegroundColor Green
    Write-Host "  .\deploy_gpu.ps1 all       # å®Œæ•´éƒ¨ç½²"
    Write-Host "  .\deploy_gpu.ps1 check     # åªæ£€æŸ¥ç¯å¢ƒ"
    Write-Host "  .\deploy_gpu.ps1 start     # åªå¯åŠ¨æœåŠ¡"
}

# æŸ¥çœ‹æ—¥å¿—
function Show-ServiceLogs {
    Log-Info "æ˜¾ç¤ºæœåŠ¡æ—¥å¿—..."
    docker compose -f docker-compose.gpu.yml logs -f --tail=50
}

# æŸ¥çœ‹çŠ¶æ€
function Show-ServiceStatus {
    Log-Info "æœåŠ¡çŠ¶æ€:"
    docker compose -f docker-compose.gpu.yml ps
    Write-Host ""
    Log-Info "GPUä½¿ç”¨æƒ…å†µ:"
    nvidia-smi --query-gpu=utilization.gpu,memory.used,memory.total --format=csv,noheader,nounits
}

# åœæ­¢æœåŠ¡
function Stop-GpuServices {
    Log-Info "åœæ­¢GPUæœåŠ¡..."
    docker compose -f docker-compose.gpu.yml down
    Log-Info "âœ… æœåŠ¡å·²åœæ­¢"
}

# æ¸…ç†ç¯å¢ƒ
function Clear-Environment {
    $response = Read-Host "è¿™å°†åˆ é™¤æ‰€æœ‰å®¹å™¨å’Œæ•°æ®ï¼Œç¡®å®šè¦ç»§ç»­å—? (y/N)"
    if ($response -match "^[yY]") {
        Log-Info "æ¸…ç†Dockerç¯å¢ƒ..."
        docker compose -f docker-compose.gpu.yml down -v
        docker system prune -f
        Log-Info "âœ… ç¯å¢ƒæ¸…ç†å®Œæˆ"
    } else {
        Log-Info "å–æ¶ˆæ¸…ç†æ“ä½œ"
    }
}

# ä¸»å‡½æ•°
function Invoke-DeploymentStep {
    param([string]$StepName)
    
    switch ($StepName) {
        "check" {
            Test-GpuEnvironment
        }
        "prepare" {
            Initialize-Environment
        }
        "build" {
            Build-DockerImages
        }
        "models" {
            Download-Models
        }
        "start" {
            Start-GpuServices
        }
        "health" {
            Test-ServiceHealth
        }
        "all" {
            Log-Info "ğŸš€ å¼€å§‹GPUæœºå™¨å®Œæ•´éƒ¨ç½²æµç¨‹..."
            Test-GpuEnvironment
            Initialize-Environment
            Build-DockerImages
            Download-Models
            Start-GpuServices
            Test-ServiceHealth
            
            Write-Host ""
            Log-Info "ğŸ‰ GPUæœºå™¨éƒ¨ç½²å®Œæˆ!" 
            Log-Info "ğŸ“Š æœåŠ¡åœ°å€:"
            Log-Info "  OCRæœåŠ¡: http://localhost:7010/docs"
            Log-Info "  ç¿»è¯‘æœåŠ¡: http://localhost:7020/docs"  
            Log-Info "  Ollama: http://localhost:11434"
        }
        "logs" {
            Show-ServiceLogs
        }
        "status" {
            Show-ServiceStatus
        }
        "stop" {
            Stop-GpuServices
        }
        "clean" {
            Clear-Environment
        }
        default {
            Show-Help
        }
    }
}

# æ‰§è¡ŒæŒ‡å®šæ­¥éª¤
Invoke-DeploymentStep -StepName $Step