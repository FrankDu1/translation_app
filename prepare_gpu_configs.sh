#!/bin/bash

# å¼€å‘æœºå™¨ - GPUé…ç½®ç®¡ç†è„šæœ¬
# ç”¨äºå‡†å¤‡å’ŒåŒæ­¥GPUæœºå™¨çš„é…ç½®

set -e

echo "ğŸ—ï¸ å¼€å‘æœºå™¨ - GPUé…ç½®ç®¡ç†"

prepare_gpu_configs() {
    echo "ğŸ“ å‡†å¤‡GPUæœºå™¨é…ç½®æ–‡ä»¶..."
    
    # ç¡®ä¿.env.gpu.exampleå­˜åœ¨å¹¶æ›´æ–°
    cat > .env.gpu.example << 'EOF'
# GPUæœºå™¨ç¯å¢ƒå˜é‡é…ç½®
CUDA_VISIBLE_DEVICES=0
OCR_ENGINES=easyocr,paddleocr
MAX_BATCH_SIZE=8
WORKER_TIMEOUT=300

# ä½¿ç”¨æœ¬åœ°Ollama
OLLAMA_HOST=http://host.docker.internal:11434
OLLAMA_MODELS=llama3.2:latest

# æ¨¡å‹è·¯å¾„
HF_HOME=/app/models/huggingface
MODEL_CACHE_DIR=/app/models
DEBUG=true
LOG_LEVEL=INFO
PYTHONPATH=/app
EOF

    # åˆ›å»ºGPUæœºå™¨çš„.envæ–‡ä»¶
    cp .env.gpu.example .env.gpu
    
    echo "âœ… GPUé…ç½®æ–‡ä»¶å‡†å¤‡å®Œæˆ"
}

validate_configs() {
    echo "ğŸ” éªŒè¯é…ç½®æ–‡ä»¶..."
    
    # æ£€æŸ¥å…³é”®æ–‡ä»¶
    files=("docker-compose.gpu.yml" ".env.gpu.example" "deploy_gpu_simple.sh")
    for file in "${files[@]}"; do
        if [ -f "$file" ]; then
            echo "âœ… $file - å­˜åœ¨"
        else
            echo "âŒ $file - ç¼ºå¤±"
        fi
    done
    
    # æ£€æŸ¥æœåŠ¡ç›®å½•
    if [ -d "services/ocr-service" ] && [ -d "services/nmt-service" ]; then
        echo "âœ… æœåŠ¡ç›®å½• - å­˜åœ¨"
    else
        echo "âŒ æœåŠ¡ç›®å½• - ç¼ºå¤±"
    fi
}

create_sync_instructions() {
    cat > GPU_SYNC_GUIDE.md << 'EOF'
# GPUæœºå™¨åŒæ­¥æŒ‡å—

## ğŸš€ GPUæœºå™¨éƒ¨ç½²æ­¥éª¤

### 1. åŒæ­¥ä»£ç 
```bash
# åœ¨GPUæœºå™¨ä¸Š
git clone <repo-url> translation_app
cd translation_app

# æˆ–æ›´æ–°ç°æœ‰ä»£ç 
git pull origin main
```

### 2. å¤åˆ¶ç¯å¢ƒé…ç½®
```bash
# ä½¿ç”¨é¢„é…ç½®çš„GPUç¯å¢ƒæ–‡ä»¶
cp .env.gpu.example .env

# æˆ–æ‰‹åŠ¨ç¼–è¾‘
nano .env
```

### 3. ç¡®ä¿Ollamaè¿è¡Œ
```bash
# æ£€æŸ¥OllamaçŠ¶æ€
ollama list
curl http://localhost:11434/api/tags
```

### 4. ä¸€é”®éƒ¨ç½²
```bash
# ç»™è„šæœ¬æ‰§è¡Œæƒé™
chmod +x deploy_gpu_simple.sh

# æ‰§è¡Œéƒ¨ç½²
./deploy_gpu_simple.sh
```

## ğŸ”§ é…ç½®è¦ç‚¹

1. **Ollamaé…ç½®**ï¼šä½¿ç”¨æœ¬åœ°Ollama (localhost:11434)
2. **GPUè®¿é—®**ï¼šç¡®ä¿Dockeræœ‰GPUè®¿é—®æƒé™
3. **ç«¯å£æ˜ å°„**ï¼šOCR(7010)ã€ç¿»è¯‘(7020)
4. **æ¨¡å‹å­˜å‚¨**ï¼š./models/ ç›®å½•ä¼šæŒä¹…åŒ–æ¨¡å‹

## ğŸ©º æ•…éšœæ’æŸ¥

### æ£€æŸ¥æœåŠ¡çŠ¶æ€
```bash
docker compose -f docker-compose.gpu.yml ps
docker compose -f docker-compose.gpu.yml logs
```

### æ£€æŸ¥å¥åº·çŠ¶æ€
```bash
curl http://localhost:7010/health
curl http://localhost:7020/health
curl http://localhost:11434/api/tags
```
EOF

    echo "âœ… åŒæ­¥æŒ‡å—åˆ›å»ºå®Œæˆ: GPU_SYNC_GUIDE.md"
}

show_git_commit_guide() {
    echo ""
    echo "ğŸ“ æäº¤åˆ°Gitçš„å»ºè®®ï¼š"
    echo ""
    echo "git add ."
    echo "git commit -m \"Complete GPU deployment configuration\""
    echo "git push origin main"
    echo ""
    echo "ç„¶ååœ¨GPUæœºå™¨ä¸Šæ‰§è¡Œï¼š"
    echo "git pull origin main"
    echo "./deploy_gpu_simple.sh"
}

# æ‰§è¡Œæ‰€æœ‰å‡†å¤‡å·¥ä½œ
case "${1:-all}" in
    "prepare")
        prepare_gpu_configs
        ;;
    "validate")
        validate_configs
        ;;
    "guide")
        create_sync_instructions
        ;;
    "all")
        prepare_gpu_configs
        validate_configs
        create_sync_instructions
        show_git_commit_guide
        ;;
    *)
        echo "ç”¨æ³•: $0 [prepare|validate|guide|all]"
        ;;
esac